{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Bert Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVLVfCfzW2KLzVUj+yhl43",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51e575b54e0b4eb0b0d7fd28120d2caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32ebc3962390413cb4cd088ce46f50d8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9530896007eb4a36a10470b3c58b0164",
              "IPY_MODEL_c92b0c080dd847bba967c6725130c375",
              "IPY_MODEL_000f59bf7e0f44c695dabe7e985f8086"
            ]
          }
        },
        "32ebc3962390413cb4cd088ce46f50d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9530896007eb4a36a10470b3c58b0164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d1b5755dbe040f992fe6150cb91b8fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93fc09cf1e0f4b29a62f26ffa8865718"
          }
        },
        "c92b0c080dd847bba967c6725130c375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94db6293aec0443c9af811a1a7abae62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 740314769,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 740314769,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a5e942c5a744acf9beaba1e9b8a6629"
          }
        },
        "000f59bf7e0f44c695dabe7e985f8086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0eaf1c21c323456fbd90fe1fa67a8868",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 706M/706M [00:34&lt;00:00, 7.76MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cd2f092ad4d409b9b0d3e097bf6c32c"
          }
        },
        "3d1b5755dbe040f992fe6150cb91b8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93fc09cf1e0f4b29a62f26ffa8865718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94db6293aec0443c9af811a1a7abae62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a5e942c5a744acf9beaba1e9b8a6629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0eaf1c21c323456fbd90fe1fa67a8868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cd2f092ad4d409b9b0d3e097bf6c32c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mucahidozcelik/NLP/blob/main/NLP_Bert_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDHRbjXOuPW8",
        "outputId": "6734d00d-7805-457d-a5da-44032082e9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "id": "wllxH5J29gWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1f9f2e-5509-4648-85ed-a10ccaa2953c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set environment as googledrive to folder \"resource\"\n",
        "data_path =  \"/resource/\"\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = \"/content/drive/My Drive/resource/\"\n",
        "\n",
        "except:\n",
        "    print(\"You are not working in Colab at the moment :(\")"
      ],
      "metadata": {
        "id": "E8_q0LkQ9gYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a6c393-9dab-43bb-d69e-e24a87088c1a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(data_path + \"dataset(westerops).xlsx\")"
      ],
      "metadata": {
        "id": "2x0-cNVSEPSi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVusjU9mEPVP",
        "outputId": "bacab57f-e751-488f-b355-01348519fe40"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1490 entries, 0 to 1489\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   comment  1490 non-null   object\n",
            " 1   Label    1490 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 23.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "K_V7JDaGEPXU",
        "outputId": "9fa60aed-ba17-42fd-8160-cb5d4f361230"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-798187a9-45d8-4b51-b263-bb31543daa5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>Metodolojinin tasarımı projelerin genel yapısı...</td>\n",
              "      <td>ProjectManagement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>Sonraki en iyi şey Evde çalışmanın önünde pek ...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1069</th>\n",
              "      <td>Bilançolar yatırımcılar için oldukça faydalıdı...</td>\n",
              "      <td>Muhasebe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>Her bir projenin bir başlatıcısı ve sponsoru o...</td>\n",
              "      <td>ProjectManagement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>Akademik yıl fakülte / sınıflandırılmamış akad...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>Projenin bu safhası; üretim projeleri içinde i...</td>\n",
              "      <td>ProjectManagement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>Bir avukat planlayabilir, süreç için profesyon...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>3. Değişimi ve belirsizliği kucaklayınGirişiml...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>Alternatif tanım : İnsan kaynakları, insanları...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>Raporda trendlerin görsel olarak gösterilmesi,...</td>\n",
              "      <td>ProjectManagement</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-798187a9-45d8-4b51-b263-bb31543daa5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-798187a9-45d8-4b51-b263-bb31543daa5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-798187a9-45d8-4b51-b263-bb31543daa5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                comment              Label\n",
              "887   Metodolojinin tasarımı projelerin genel yapısı...  ProjectManagement\n",
              "220   Sonraki en iyi şey Evde çalışmanın önünde pek ...      HumanResource\n",
              "1069  Bilançolar yatırımcılar için oldukça faydalıdı...           Muhasebe\n",
              "536   Her bir projenin bir başlatıcısı ve sponsoru o...  ProjectManagement\n",
              "496   Akademik yıl fakülte / sınıflandırılmamış akad...      HumanResource\n",
              "808   Projenin bu safhası; üretim projeleri içinde i...  ProjectManagement\n",
              "161   Bir avukat planlayabilir, süreç için profesyon...      HumanResource\n",
              "99    3. Değişimi ve belirsizliği kucaklayınGirişiml...      HumanResource\n",
              "448   Alternatif tanım : İnsan kaynakları, insanları...      HumanResource\n",
              "515   Raporda trendlerin görsel olarak gösterilmesi,...  ProjectManagement"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "3YksUA_jCURw",
        "outputId": "674e4bf8-61a2-4bb2-c276-ceec002c6af3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-31e2dc0b-3504-4d81-87b3-b145b50773ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tüm bunların yanı sıra çalışanların ücretli iz...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Çalışanların hafta tatilleri ve resmi tatiller...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ücretsiz izin çerçevesinde iş sözleşmesi askıy...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Memurlar hastalandıkları ve bu hastalıklarını ...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bilindiği üzere 657 sayılı Kanunda devlet memu...</td>\n",
              "      <td>HumanResource</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31e2dc0b-3504-4d81-87b3-b145b50773ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31e2dc0b-3504-4d81-87b3-b145b50773ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31e2dc0b-3504-4d81-87b3-b145b50773ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             comment          Label\n",
              "0  Tüm bunların yanı sıra çalışanların ücretli iz...  HumanResource\n",
              "1  Çalışanların hafta tatilleri ve resmi tatiller...  HumanResource\n",
              "2  Ücretsiz izin çerçevesinde iş sözleşmesi askıy...  HumanResource\n",
              "3  Memurlar hastalandıkları ve bu hastalıklarını ...  HumanResource\n",
              "4  Bilindiği üzere 657 sayılı Kanunda devlet memu...  HumanResource"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Label').size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJZYscfiEPZq",
        "outputId": "7d02647b-208f-4e95-a1b3-18086ca161bf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "HumanResource        511\n",
              "Muhasebe             478\n",
              "ProjectManagement    501\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kategorik olan label'ları modelde kullanabilmemiz için kategori kolonunu encode etmemiz gerekiyor."
      ],
      "metadata": {
        "id": "rsfYWG-_FuwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded_categories'] = LabelEncoder().fit_transform(df['Label'])"
      ],
      "metadata": {
        "id": "bwj_erbxEPbv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "_o7sZDdrEPd1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df.comment.values"
      ],
      "metadata": {
        "id": "W4iIZgRSEPgL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 200"
      ],
      "metadata": {
        "id": "QowcdNenEPiL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "girdi uzunluğunu maksimum 200 olarak belirtiyoruz."
      ],
      "metadata": {
        "id": "QjTBZaHYNcdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = df.groupby('Label').apply(lambda x : x.sample(frac = 0.8))\n",
        "test = pd.concat([df,training]).drop_duplicates(keep=False)"
      ],
      "metadata": {
        "id": "bI9HHyTT9gaz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "burada elimizdeki metin verisini %80 ve %20 oranıyla, sırasıyla training ve test olarak ikiye bölüyoruz"
      ],
      "metadata": {
        "id": "VIuOeM_INd0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training: \", len(training))\n",
        "print(\"Test: \", len(test))"
      ],
      "metadata": {
        "id": "DQ14fDAR9gc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20de1f4-95df-4186-91de-8ba065e50233"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  1192\n",
            "Test:  296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_texts = training.comment.values\n",
        "training_labels = training.encoded_categories.values"
      ],
      "metadata": {
        "id": "TDda8YF0Fhew"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bu kısımda metin verisini modelde kullanmak üzere işliyoruz. öncelikle cümledeki kelimeler indirdiğimiz tokenizer ile tokenize ediliyor, sonrasında sınıflandırma probleminin çözülebilmesi için gerekli olan token'lar cümlenin sonuna ve başına ekleniyor. cümle maksimum uzunluktan kısaysa, input vektörümüz sabit uzunlukta olduğu için boşluklar dolduruluyor, uzunsa metin limit kadar kelime ile ifade ediliyor. attention mask'leri oluşturuluyor ve metinler işlemin sonucunda tensor objesi olarak geri dönüyor.\n",
        "\n",
        "aşağıdaki çıktıda da görüldüğü üzere, metindeki kelimeler tokenizer'daki kelimelerin id'leri ile ifade ediliyor ve bu şekilde işleme sokuluyor."
      ],
      "metadata": {
        "id": "GiG7ovy2NscM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for comment in training_texts:\n",
        "    if type(comment) == str: \n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                        comment ,                     \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = max_len,      \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(training_labels)\n",
        "\n",
        "print('Original: ', training_texts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_cAYjhrFhii",
        "outputId": "4d28dfe3-9dda-4004-8cb0-e9787415a99e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Örnek 2 - Tatil Talep Mektubu\n",
            "Konu:  Tatil isteği [DATE] - [DATE]\n",
            "Sayın [Yöneticinin Adı],\n",
            "[TARİH - TARİH] için tatil talebinde bulunmak istiyorum. Ailemle tatil yapalı neredeyse 5 yıl oldu. Tatil saatlerimin bir kısmı çok ihtiyaç duyulan aile zamanı için kullanmak istiyorum. Şu anda 125 saatim var ve 40 tanesini kullanmak istiyorum.\n",
            "Şu anda tüm çalışmalarım tamamlandı. Bu yolculuk için ayrılmadan önce, bekleyen tüm işlerin önceden tamamlanacağından da emin olacağım. Benim yokluğumda benim yerimi dolduranın, yapacak çok şeyi olmayacağından emin olacağım.\n",
            "Bildiğiniz gibi, çalışkan biriyim ve haftada 60 saatten fazla çalışıyorum. Tazelenmenin ve tükenmemenin iyi bir yolu, arada bir tatil yapmaktır.\n",
            "Uzun zamandır gecikmiş olduğumu hissediyorum. Şirket talepleri için birkaç kez geziyi beklemeye aldım. Ailemle geçirmek için biraz zamanım olsun istiyorum.\n",
            "Resmi şirket Tatil Talep Formunu doldurdum ve inceleniz için ekledim. Seyahatimi planlayabilmem için lütfen bana yazılı olarak cevap verin.\n",
            "İçtenlikle,\n",
            "Adınız eklerin\n",
            "listesi\n",
            "Token IDs: tensor([     2,  56899,     22,     17,   4877,   3912,  14004,   2580,     30,\n",
            "          4877,   2946,   2242,     37,  50660,     39,     17,     37,  50660,\n",
            "            39,   4538,     37, 110616,   2047,   3378,     39,     16,     37,\n",
            "          2388,     17,   2388,     39,   8059,   4877,  13443,   7842,   3719,\n",
            "            18,  42377,   4877,   9518,   1945,   5585,     25,   2124,   2069,\n",
            "            18,   4877,   8628,   3240,   1947,   5781,   6110,   4426,  11514,\n",
            "          4210,   6108,   8059,   6483,   3719,     18,   2366,   3628,  14206,\n",
            "         83758,   2130,   1946,   4030,  20607,   6483,   3719,     18,   2366,\n",
            "          3628,  20900,  52565,   3066,   1023,  12586,     18,   1964,   7336,\n",
            "          8059,  36766,  18094,     16,   8414,  20900,  76166,   1009,  91466,\n",
            "          8907,   8550,  95517,   1972,   4059,  29077,  22278,     18,   2633,\n",
            "          2351,  40947,  41526,   2633,  50044,  18230,   1930,     16,   4445,\n",
            "          6110,  35403,   4608, 107815,  20076,   4059,  29077,  22278,     18,\n",
            "         33212,  18797,   2166,     16,  52565,   2710,  19464,   1946,   7933,\n",
            "          4720,  17949,   2554,  52565,   4113,     18,  86953,   3891,   1946,\n",
            "         38720,   1929,  10340,   8117,   2370,   1947,   3766,     16,   4109,\n",
            "          1947,   4877,  29947,     18,   2804,   8602,   7174,   7570,  88039,\n",
            "         11629,     18,  21876,  13492,   8059,  63139,   3098,  85918,  23744,\n",
            "          6443,     18,  42377,  38529,   2044,   8059,   3043,  30157,   3284,\n",
            "          3719,     18,   4140,  21876,   4877,   3912,  16983,  71986,   1946,\n",
            "          6878,   1952,   8059,  32595,     18,  29571,   2932,  40830,   1984,\n",
            "         20171,   1023,   8059,  35499,   2789,   3624,   2095,   3801,   8867,\n",
            "            18,      3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "ZqMRnJMhFhlh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "oluşturduğumuz tensor verisini modele vermek üzere dataloader değişkenine dönüştürüyoruz."
      ],
      "metadata": {
        "id": "F6exvhWIcKd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "metadata": {
        "id": "beS9iov2FhoB"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_categories = len(df['encoded_categories'].unique())"
      ],
      "metadata": {
        "id": "tkNxJUiAFhqe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dbmdz/bert-base-turkish-128k-uncased\",\n",
        "    num_labels = number_of_categories, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "51e575b54e0b4eb0b0d7fd28120d2caf",
            "32ebc3962390413cb4cd088ce46f50d8",
            "9530896007eb4a36a10470b3c58b0164",
            "c92b0c080dd847bba967c6725130c375",
            "000f59bf7e0f44c695dabe7e985f8086",
            "3d1b5755dbe040f992fe6150cb91b8fc",
            "93fc09cf1e0f4b29a62f26ffa8865718",
            "94db6293aec0443c9af811a1a7abae62",
            "5a5e942c5a744acf9beaba1e9b8a6629",
            "0eaf1c21c323456fbd90fe1fa67a8868",
            "3cd2f092ad4d409b9b0d3e097bf6c32c"
          ]
        },
        "id": "26iDpPbiFhtM",
        "outputId": "f3117edf-a22e-47f5-f3c8-b99a68e40c15"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51e575b54e0b4eb0b0d7fd28120d2caf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/706M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(128000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training'den önceki son adımda, toplam training adım sayısını ve kaç kere training yapılacağı sayısını belirliyoruz. bu sayıların yanında, öğrenmenin daha verimli olabilmesi ve learning rate optimizasyonu için bir scheduler yaratılıyor ve optimizer olarak Adam Optimizer kullanılıyoruz."
      ],
      "metadata": {
        "id": "Ztjmx1guDLZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5,\n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtNmC2olFhwM",
        "outputId": "b6ed3504-d936-4a5e-9060-459544c30fc9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "dpgEuwlwdifH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training aşamasına geçmeden önce seed değerini sabit bir değere eşitliyoruz ki, bütün deneylerimizde aynı sonucu alabilmek için ."
      ],
      "metadata": {
        "id": "YXh1Gc4pDS3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "training, toplam bölüm (epoch) sayısı kadar, bizde 4, kez yapılıyor. yukarıda training verisetini dataloader'a aktarmıştık, girdileri 32'şer 32'şer alıp modeli besliyoruz ve training başlıyor. her bölüm başlamadan önce optimize edilecek loss değeri sıfırlanıyor. modelin train() metotu çağırılıyor. çünkü test kısmında eval() metotu çağırılıyor. modelin katmanları train ve eval metotlarında farklı olarak davranıyor. dataloader'daki değerler GPU'ya aktarılıyor, gradient değerleri sıfırlanıyor ve output (logit) değerleri oluşuyor ve buna bağlı olarak loss değeri hesaplanıyor. backpropogation ile gradient'ler tekrar hesaplanıyor ve son olarak da learnig rate'le beraber parametreler de optimize ediliyor. her bölümün sonunda ortalama loss'u inceleyebiliriz."
      ],
      "metadata": {
        "id": "Y7lIMCsdESaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 1903\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "        output = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = output['loss']\n",
        "        logits = output['logits']\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh7Gfi1ddiou",
        "outputId": "7d160493-ea31-4290-b62a-7508f928220e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Batch    10  of     38.    Elapsed: 0:00:11.\n",
            "Batch    20  of     38.    Elapsed: 0:00:22.\n",
            "Batch    30  of     38.    Elapsed: 0:00:33.\n",
            "Average training loss: 0.50\n",
            "Training epoch took: 0:00:41\n",
            "======== Epoch 2 / 4 ========\n",
            "Batch    10  of     38.    Elapsed: 0:00:11.\n",
            "Batch    20  of     38.    Elapsed: 0:00:23.\n",
            "Batch    30  of     38.    Elapsed: 0:00:35.\n",
            "Average training loss: 0.07\n",
            "Training epoch took: 0:00:43\n",
            "======== Epoch 3 / 4 ========\n",
            "Batch    10  of     38.    Elapsed: 0:00:11.\n",
            "Batch    20  of     38.    Elapsed: 0:00:23.\n",
            "Batch    30  of     38.    Elapsed: 0:00:34.\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:42\n",
            "======== Epoch 4 / 4 ========\n",
            "Batch    10  of     38.    Elapsed: 0:00:11.\n",
            "Batch    20  of     38.    Elapsed: 0:00:23.\n",
            "Batch    30  of     38.    Elapsed: 0:00:34.\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:43\n",
            "Training completed in 0:02:49 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training'deki model performansı incelemek için loss'daki düşüşü inceliyoruz."
      ],
      "metadata": {
        "id": "4tU1FuM2Ebz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "plt.plot(df_stats['Training Loss'], label=\"Training\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tQl69Qzodisx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3c14402e-5cff-490f-b000-1618a8ce8760"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training verisetinde olduğu gibi, test veriseti için de bir dataloader oluşturuyoruz."
      ],
      "metadata": {
        "id": "STa7Zv0nEgQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = test.comment.values\n",
        "test_labels = test.encoded_categories.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in test_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                     \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = max_len,          \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt',   \n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "jHTiVNDKdiv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6e9dfe-e1f3-4ebe-f619-7d43eb717177"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test verisini kullanarak modele sonuçları tahmin ettiriyoruz. batch değerimiz 32 olduğu için, model training'de olduğu gibi prediction kısmında da 32'şer 32'şer input'ları modele veriyor. o yüzden flatten fonksiyonu ile bütün sonuçları tek bir listede topluyoruz ve prediction_set değişkeninde saklıyoruz."
      ],
      "metadata": {
        "id": "U9DDXVkoEtHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction started on test data')\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('Prediction completed')"
      ],
      "metadata": {
        "id": "ok_LX-o4FhzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9806975b-882d-41b7-87a8-7fe9798821bc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction started on test data\n",
            "Prediction completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  prediction_set.append(pred_labels_i)\n",
        "\n",
        "prediction_scores = [item for sublist in prediction_set for item in sublist]"
      ],
      "metadata": {
        "id": "VE49LmYk9gfB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bu bir sınıflandırma problemi olduğu için performans metriklerinden F-score'u kullanmak istedim. bu kısımda Precision, Recall ve F-score değerlerini çıkartıyoruz, modelin performansını gözlemliyoruz."
      ],
      "metadata": {
        "id": "3fyWotTWE7Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_score = f1_score(test_labels, prediction_scores, average='macro')\n",
        "precision = precision_score(test_labels, prediction_scores, average='macro')\n",
        "recall = recall_score(test_labels, prediction_scores, average='macro')"
      ],
      "metadata": {
        "id": "lPjttZe8vIKm"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "görüldüğü üzere, kısıtlı bir veriseti ile bile iyi bir performans edilebiliyor. verisetinin kısıtlı olmasının dışında, cümlelerde 250'den fazla kelime olmasına rağmen, input layer kısmında her cümle 250 kelimeyle ifade edilip yüksek F-score elde edilebildi."
      ],
      "metadata": {
        "id": "7siwc18rFC6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F-Score: \", f_score)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"Precision: \", precision)"
      ],
      "metadata": {
        "id": "R5rqCJRnvIM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b3cb98-44a6-4b4d-f05d-17ec0d89b22a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score:  0.9595919236149122\n",
            "Recall:  0.9594302588153552\n",
            "Precision:  0.959973973710805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))"
      ],
      "metadata": {
        "id": "OT5A1FudEU2z"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = report.rename(columns={'0':'HumanResource',\n",
        "                          '1':'Muhasebe',\n",
        "                          '2':'ProjectManagement',\n",
        "                          })"
      ],
      "metadata": {
        "id": "V9_XFnpWEUyu"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "StLV_x8mEUsO",
        "outputId": "5086b501-108b-406d-b5fa-57ea974e1858"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9da66ba8-8d38-4c80-a36a-e9c054083b80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HumanResource</th>\n",
              "      <th>Muhasebe</th>\n",
              "      <th>ProjectManagement</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.979798</td>\n",
              "      <td>0.968085</td>\n",
              "      <td>0.932039</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.959974</td>\n",
              "      <td>0.959904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.960396</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.959430</td>\n",
              "      <td>0.959459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.970000</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.945813</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.959592</td>\n",
              "      <td>0.959570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>101.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>296.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9da66ba8-8d38-4c80-a36a-e9c054083b80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9da66ba8-8d38-4c80-a36a-e9c054083b80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9da66ba8-8d38-4c80-a36a-e9c054083b80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           HumanResource   Muhasebe  ...   macro avg  weighted avg\n",
              "precision       0.979798   0.968085  ...    0.959974      0.959904\n",
              "recall          0.960396   0.957895  ...    0.959430      0.959459\n",
              "f1-score        0.970000   0.962963  ...    0.959592      0.959570\n",
              "support       101.000000  95.000000  ...  296.000000    296.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}